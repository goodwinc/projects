{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'body_type', 'diet', 'drinks', 'drugs', 'education', 'essay0',\n",
       "       'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', 'essay7',\n",
       "       'essay8', 'essay9', 'ethnicity', 'height', 'income', 'job',\n",
       "       'last_online', 'location', 'offspring', 'orientation', 'pets',\n",
       "       'religion', 'sex', 'sign', 'smokes', 'speaks', 'status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essay0    about me:<br />\\n<br />\\ni would love to think...\n",
       "essay1    currently working as an international agent fo...\n",
       "essay2    making people laugh.<br />\\nranting about a go...\n",
       "essay3    the way i look. i am a six foot half asian, ha...\n",
       "essay4    books:<br />\\nabsurdistan, the republic, of mi...\n",
       "essay5    food.<br />\\nwater.<br />\\ncell phone.<br />\\n...\n",
       "essay6                          duality and humorous things\n",
       "essay7    trying to find someone to hang out with. i am ...\n",
       "essay8    i am new to california and looking for someone...\n",
       "essay9    you want to be swept off your feet!<br />\\nyou...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0][['essay' + str(i) for i in range(10)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age              int64\n",
       "body_type       object\n",
       "diet            object\n",
       "drinks          object\n",
       "drugs           object\n",
       "education       object\n",
       "essay0          object\n",
       "essay1          object\n",
       "essay2          object\n",
       "essay3          object\n",
       "essay4          object\n",
       "essay5          object\n",
       "essay6          object\n",
       "essay7          object\n",
       "essay8          object\n",
       "essay9          object\n",
       "ethnicity       object\n",
       "height         float64\n",
       "income           int64\n",
       "job             object\n",
       "last_online     object\n",
       "location        object\n",
       "offspring       object\n",
       "orientation     object\n",
       "pets            object\n",
       "religion        object\n",
       "sex             object\n",
       "sign            object\n",
       "smokes          object\n",
       "speaks          object\n",
       "status          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "body_type       5296\n",
       "diet           24395\n",
       "drinks          2985\n",
       "drugs          14080\n",
       "education       6628\n",
       "essay0          5488\n",
       "essay1          7572\n",
       "essay2          9638\n",
       "essay3         11476\n",
       "essay4         10537\n",
       "essay5         10850\n",
       "essay6         13771\n",
       "essay7         12451\n",
       "essay8         19225\n",
       "essay9         12603\n",
       "ethnicity       5680\n",
       "height             3\n",
       "income             0\n",
       "job             8198\n",
       "last_online        0\n",
       "location           0\n",
       "offspring      35561\n",
       "orientation        0\n",
       "pets           19921\n",
       "religion       20226\n",
       "sex                0\n",
       "sign           11056\n",
       "smokes          5512\n",
       "speaks            50\n",
       "status             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['essay' + str(i) for i in range(10)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(lambda row: ' '.join(row), axis=1).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    stripped_text = soup.get_text()\n",
    "    return stripped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "    text = strip_html_tags(text)\n",
    "    \n",
    "    remove_punct = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(remove_punct)\n",
    "    \n",
    "    remove_digits = str.maketrans('', '', string.digits)\n",
    "    text = text.lower().translate(remove_digits)\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "    tokens_stop = [y for y in tokens if y not in stop_words]\n",
    "    \n",
    "    stemmer = SnowballStemmer('english')\n",
    "    tokens_stem = [stemmer.stem(y) for y in tokens_stop]\n",
    "    \n",
    "    return tokens_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35829.000000\n",
       "mean        32.018588\n",
       "std          9.032881\n",
       "min         18.000000\n",
       "25%         26.000000\n",
       "50%         30.000000\n",
       "75%         36.000000\n",
       "max        109.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.sex=='m'].age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24117.000000\n",
       "mean        32.818220\n",
       "std         10.025385\n",
       "min         18.000000\n",
       "25%         26.000000\n",
       "50%         30.000000\n",
       "75%         37.000000\n",
       "max        110.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.sex=='f'].age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f04bf404b3fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 266\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-f51d1adea1f0>\u001b[0m in \u001b[0;36mcustom_tokenizer\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mstemmer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtokens_stem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokens_stem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-f51d1adea1f0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mstemmer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtokens_stem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokens_stem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/stem/snowball.py\u001b[0m in \u001b[0;36mstem\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m   1488\u001b[0m         \u001b[0;31m# STEP 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__step3_suffixes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1491\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mr1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tional\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(tokenizer=custom_tokenizer)\n",
    "X_cv = cv.fit_transform(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('words_sparse_matrix.pkl', 'wb') as handle:\n",
    "    pickle.dump(X_cv, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('countvec.pkl', 'wb') as f:\n",
    "    pickle.dump(cv, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('words_sparse_matrix.pkl', 'rb') as handle:\n",
    "    X_cv = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aaaa',\n",
       " 'aaaaa',\n",
       " 'aaaaaa',\n",
       " 'aaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaand',\n",
       " 'aaaaaaaaaaaaaaaaaaahhhhhhhhh',\n",
       " 'aaaaaaaaaaaand',\n",
       " 'aaaaaaaaaaand',\n",
       " 'aaaaaaaaaajdkjdjdjsjjsjsjdjsndndjdjsnsnmsmsmddmmsmsmdmdmdmdmdmdnxnxnckcjffkf',\n",
       " 'aaaaaaaaaand',\n",
       " 'aaaaaaaaall',\n",
       " 'aaaaaaaah',\n",
       " 'aaaaaaaand',\n",
       " 'aaaaaaahhhhhh',\n",
       " 'aaaaaaand',\n",
       " 'aaaaaaauaiagajakalpplth',\n",
       " 'aaaaaag',\n",
       " 'aaaaaah',\n",
       " 'aaaaaahhh',\n",
       " 'aaaaaalmost',\n",
       " 'aaaaaand',\n",
       " 'aaaaaandeat',\n",
       " 'aaaaah',\n",
       " 'aaaaall',\n",
       " 'aaaaalll',\n",
       " 'aaaaalllllllll',\n",
       " 'aaaaalllrright',\n",
       " 'aaaaand',\n",
       " 'aaaaannndddd',\n",
       " 'aaaaannnnnd',\n",
       " 'aaaaawwwwwwwwwwww',\n",
       " 'aaaaayyyyyi',\n",
       " 'aaaaggh',\n",
       " 'aaaah',\n",
       " 'aaaahh',\n",
       " 'aaaahhh',\n",
       " 'aaaahhhh',\n",
       " 'aaaallrighti',\n",
       " 'aaaand',\n",
       " 'aaaandit',\n",
       " 'aaaandthat',\n",
       " 'aaaani',\n",
       " 'aaaannnd',\n",
       " 'aaaannnddddd',\n",
       " 'aaaanyhoo',\n",
       " 'aaaanyth',\n",
       " 'aaaanyway',\n",
       " 'aaaaoooh',\n",
       " 'aaaasss',\n",
       " 'aaaawwweessooomme',\n",
       " 'aaaawwww',\n",
       " 'aaaayyy',\n",
       " 'aaabuuunnncch',\n",
       " 'aaagh',\n",
       " 'aaah',\n",
       " 'aaahahaha',\n",
       " 'aaahh',\n",
       " 'aaahhh',\n",
       " 'aaahyay',\n",
       " 'aaaiiiieee',\n",
       " 'aaaladdin',\n",
       " 'aaallllll',\n",
       " 'aaallllllll',\n",
       " 'aaam',\n",
       " 'aaammmaaaz',\n",
       " 'aaand',\n",
       " 'aaannd',\n",
       " 'aaannnd',\n",
       " 'aaannndddd',\n",
       " 'aaannnnd',\n",
       " 'aaarggh',\n",
       " 'aaargh',\n",
       " 'aaarrggghhhh',\n",
       " 'aaarrrghh',\n",
       " 'aaarrrrggg',\n",
       " 'aaarrrrrrdman',\n",
       " 'aaarrrrtttaaaaxxx',\n",
       " 'aaaw',\n",
       " 'aaawesom',\n",
       " 'aaaww',\n",
       " 'aab',\n",
       " 'aabus',\n",
       " 'aacm',\n",
       " 'aacr',\n",
       " 'aactiv',\n",
       " 'aadegre',\n",
       " 'aaeriel',\n",
       " 'aag',\n",
       " 'aagghhh',\n",
       " 'aah',\n",
       " 'aahhhh',\n",
       " 'aahhhhahaha',\n",
       " 'aahyay',\n",
       " 'aahz',\n",
       " 'aai',\n",
       " 'aaight',\n",
       " 'aait',\n",
       " 'aaj',\n",
       " 'aajonus',\n",
       " 'aakerkevin',\n",
       " 'aakissingsexdancingprayinglov',\n",
       " 'aalaap',\n",
       " 'aalborg',\n",
       " 'aalfr',\n",
       " 'aaliayah',\n",
       " 'aaliya',\n",
       " 'aaliyah',\n",
       " 'aaliyahandfleetwood',\n",
       " 'aalll',\n",
       " 'aalso',\n",
       " 'aalto',\n",
       " 'aalyiah',\n",
       " 'aam',\n",
       " 'aamayz',\n",
       " 'aambr',\n",
       " 'aamina',\n",
       " 'aamir',\n",
       " 'aamnesiaceraserera',\n",
       " 'aan',\n",
       " 'aanabahquajahajajakskanajjahajabajanajaaajhaiaoauaiakakakjjznjakajauauahyaishahjahghhjjzojzjzjjhikaonhab',\n",
       " 'aand',\n",
       " 'aang',\n",
       " 'aangel',\n",
       " 'aannndddd',\n",
       " 'aaoohhh',\n",
       " 'aap',\n",
       " 'aapk',\n",
       " 'aapko',\n",
       " 'aapl',\n",
       " 'aapolog',\n",
       " 'aar',\n",
       " 'aardman',\n",
       " 'aardvark',\n",
       " 'aardvarkttx',\n",
       " 'aarecoveri',\n",
       " 'aarggh',\n",
       " 'aargghpthfftblergh',\n",
       " 'aargh',\n",
       " 'aarghtravel',\n",
       " 'aari',\n",
       " 'aarlo',\n",
       " 'aaron',\n",
       " 'aaronofski',\n",
       " 'aaronovitch',\n",
       " 'aaronovski',\n",
       " 'aarp',\n",
       " 'aarrggghh',\n",
       " 'aarron',\n",
       " 'aartaud',\n",
       " 'aashto',\n",
       " 'aasif',\n",
       " 'aasimov',\n",
       " 'aasteriskasterisk',\n",
       " 'aataaaacctca',\n",
       " 'aatar',\n",
       " 'aathon',\n",
       " 'aau',\n",
       " 'aauima',\n",
       " 'aawww',\n",
       " 'aawwwlik',\n",
       " 'ab',\n",
       " 'aba',\n",
       " 'ababa',\n",
       " 'abacha',\n",
       " 'aback',\n",
       " 'abacus',\n",
       " 'abaddon',\n",
       " 'abado',\n",
       " 'abadstorytel',\n",
       " 'abagail',\n",
       " 'abagnal',\n",
       " 'abair',\n",
       " 'abakus',\n",
       " 'abalama',\n",
       " 'abalancedperspect',\n",
       " 'abalon',\n",
       " 'abaloneb',\n",
       " 'abandon',\n",
       " 'abandonedfound',\n",
       " 'abandonno',\n",
       " 'abandonsometim',\n",
       " 'abangbalen',\n",
       " 'abani',\n",
       " 'abarat',\n",
       " 'abarim',\n",
       " 'abarrotado',\n",
       " 'abas',\n",
       " 'abash',\n",
       " 'abasin',\n",
       " 'abasolm',\n",
       " 'abat',\n",
       " 'abati',\n",
       " 'abayomi',\n",
       " 'abb',\n",
       " 'abba',\n",
       " 'abbado',\n",
       " 'abbasara',\n",
       " 'abbastanza',\n",
       " 'abbayep',\n",
       " 'abbess',\n",
       " 'abbey',\n",
       " 'abbeya',\n",
       " 'abbeyan',\n",
       " 'abbeybut',\n",
       " 'abbeyi',\n",
       " 'abbeyish',\n",
       " 'abbeykq',\n",
       " 'abbeyliteraturefresh',\n",
       " 'abbhorsen',\n",
       " 'abbi',\n",
       " 'abbilona',\n",
       " 'abbondanza',\n",
       " 'abbot',\n",
       " 'abbott',\n",
       " 'abbras',\n",
       " 'abbrev',\n",
       " 'abbrevi',\n",
       " 'abbreviationyou',\n",
       " 'abbslol',\n",
       " 'abbuehl',\n",
       " 'abbvtion',\n",
       " 'abbydog',\n",
       " 'abc',\n",
       " 'abcamerican',\n",
       " 'abcand',\n",
       " 'abccom',\n",
       " 'abcd',\n",
       " 'abcdefghijklmnopqrstuvwxyz',\n",
       " 'abcess',\n",
       " 'abcfamili',\n",
       " 'abcnewscom',\n",
       " 'abd',\n",
       " 'abdc',\n",
       " 'abdel',\n",
       " 'abdelhalim',\n",
       " 'abdelli',\n",
       " 'abdoh',\n",
       " 'abdollio',\n",
       " 'abdomen',\n",
       " 'abdomin',\n",
       " 'abduct',\n",
       " 'abdul',\n",
       " 'abdulah',\n",
       " 'abduljabbar',\n",
       " 'abduljason',\n",
       " 'abdullah',\n",
       " 'abe',\n",
       " 'abearham',\n",
       " 'abeauti',\n",
       " 'abel',\n",
       " 'abelar',\n",
       " 'abelard',\n",
       " 'abelian',\n",
       " 'abelton',\n",
       " 'abeni',\n",
       " 'abenobashi',\n",
       " 'aber',\n",
       " 'abercrombi',\n",
       " 'abercrombieben',\n",
       " 'abercrombiefitch',\n",
       " 'aberdeen',\n",
       " 'aberham',\n",
       " 'aberlour',\n",
       " 'aberr',\n",
       " 'aberrantphasebandcampcom',\n",
       " 'aberrationworri',\n",
       " 'abet',\n",
       " 'abfab',\n",
       " 'abfabyou',\n",
       " 'abgenix',\n",
       " 'abha',\n",
       " 'abhor',\n",
       " 'abhorr',\n",
       " 'abhorreb',\n",
       " 'abhorsen',\n",
       " 'abi',\n",
       " 'abicheerfulfunnycar',\n",
       " 'abichuela',\n",
       " 'abid',\n",
       " 'abida',\n",
       " 'abidexter',\n",
       " 'abidjan',\n",
       " 'abierc',\n",
       " 'abierta',\n",
       " 'abierto',\n",
       " 'abigail',\n",
       " 'abil',\n",
       " 'abilen',\n",
       " 'abili',\n",
       " 'abilit',\n",
       " 'abilitiesand',\n",
       " 'abilitiescontinu',\n",
       " 'abilitiesmusicpoliticsb',\n",
       " 'abilitieswhich',\n",
       " 'abilityc',\n",
       " 'abilitydesir',\n",
       " 'abilitymost',\n",
       " 'abilitywilling',\n",
       " 'abilon',\n",
       " 'abilti',\n",
       " 'abimbev',\n",
       " 'abingdon',\n",
       " 'abirthdaygirl',\n",
       " 'abish',\n",
       " 'abit',\n",
       " 'abita',\n",
       " 'abiti',\n",
       " 'abjad',\n",
       " 'abject',\n",
       " 'abjeez',\n",
       " 'abjo',\n",
       " 'abkhazia',\n",
       " 'abl',\n",
       " 'ablat',\n",
       " 'ablaz',\n",
       " 'ablebodi',\n",
       " 'ableep',\n",
       " 'ableism',\n",
       " 'ableist',\n",
       " 'ableite',\n",
       " 'ablelist',\n",
       " 'ableman',\n",
       " 'ablest',\n",
       " 'ableton',\n",
       " 'abletoncraft',\n",
       " 'ablewil',\n",
       " 'abliiti',\n",
       " 'ablism',\n",
       " 'abliti',\n",
       " 'ablout',\n",
       " 'ablut',\n",
       " 'abm',\n",
       " 'abner',\n",
       " 'abnett',\n",
       " 'abney',\n",
       " 'abnkkbsnplako',\n",
       " 'abnorm',\n",
       " 'abnormaluniqu',\n",
       " 'aboard',\n",
       " 'aboaut',\n",
       " 'abod',\n",
       " 'aboforcen',\n",
       " 'aboit',\n",
       " 'abolish',\n",
       " 'abolit',\n",
       " 'abolitionist',\n",
       " 'abolitionreform',\n",
       " 'abolon',\n",
       " 'abomb',\n",
       " 'abomin',\n",
       " 'abon',\n",
       " 'abook',\n",
       " 'abookworm',\n",
       " 'abooooooot',\n",
       " 'aboot',\n",
       " 'abootand',\n",
       " 'aboout',\n",
       " 'aborigin',\n",
       " 'aborrecimiento',\n",
       " 'abort',\n",
       " 'aborym',\n",
       " 'aboslut',\n",
       " 'abot',\n",
       " 'abou',\n",
       " 'aboud',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'abouta',\n",
       " 'aboutaft',\n",
       " 'aboutalso',\n",
       " 'aboutand',\n",
       " 'aboutanyth',\n",
       " 'aboutar',\n",
       " 'aboutart',\n",
       " 'aboutb',\n",
       " 'aboutbecaus',\n",
       " 'aboutbeliev',\n",
       " 'aboutbi',\n",
       " 'aboutbut',\n",
       " 'aboutcasu',\n",
       " 'aboutchillin',\n",
       " 'aboutcompli',\n",
       " 'aboutdinn',\n",
       " 'aboutdiscov',\n",
       " 'aboutdrink',\n",
       " 'abouteg',\n",
       " 'aboutengag',\n",
       " 'aboutenjoy',\n",
       " 'abouteveryth',\n",
       " 'aboutexagger',\n",
       " 'aboutexploreexperi',\n",
       " 'aboutfamili',\n",
       " 'aboutfilm',\n",
       " 'aboutfood',\n",
       " 'aboutfor',\n",
       " 'aboutget',\n",
       " 'aboutgood',\n",
       " 'abouthav',\n",
       " 'abouthonesti',\n",
       " 'abouthowothersfeelthinkingabout',\n",
       " 'abouti',\n",
       " 'aboutid',\n",
       " 'aboutil',\n",
       " 'aboutim',\n",
       " 'aboutit',\n",
       " 'aboutjust',\n",
       " 'aboutl',\n",
       " 'aboutlik',\n",
       " 'aboutlisten',\n",
       " 'aboutlong',\n",
       " 'aboutlook',\n",
       " 'aboutmak',\n",
       " 'aboutmayb',\n",
       " 'aboutmeccdy',\n",
       " 'aboutmeferociousj',\n",
       " 'aboutmi',\n",
       " 'aboutnow',\n",
       " 'abouton',\n",
       " 'aboutor',\n",
       " 'aboutoth',\n",
       " 'aboutplan',\n",
       " 'aboutpractic',\n",
       " 'aboutr',\n",
       " 'aboutresearch',\n",
       " 'aboutright',\n",
       " 'aboutrun',\n",
       " 'aboutse',\n",
       " 'aboutseri',\n",
       " 'aboutso',\n",
       " 'aboutsometh',\n",
       " 'aboutsometim',\n",
       " 'aboutstuff',\n",
       " 'aboutth',\n",
       " 'aboutthat',\n",
       " 'abouttim',\n",
       " 'abouttolaunch',\n",
       " 'abouttrad',\n",
       " 'abouttwitt',\n",
       " 'aboutusu',\n",
       " 'aboutw',\n",
       " 'aboutwaitwel',\n",
       " 'aboutwel',\n",
       " 'aboutwhat',\n",
       " 'aboutwhen',\n",
       " 'aboutwheth',\n",
       " 'aboutwil',\n",
       " 'aboutwith',\n",
       " 'aboutwond',\n",
       " 'aboutwork',\n",
       " 'aboutyou',\n",
       " 'aboutyoul',\n",
       " 'aboutyoung',\n",
       " 'aboutyour',\n",
       " 'aboveal',\n",
       " 'aboveand',\n",
       " 'aboveandtotheright',\n",
       " 'aboveaverag',\n",
       " 'abovebeyond',\n",
       " 'abovebut',\n",
       " 'aboveeek',\n",
       " 'aboveeven',\n",
       " 'abovehahahaha',\n",
       " 'abovehi',\n",
       " 'abovehmmm',\n",
       " 'abovei',\n",
       " 'aboveif',\n",
       " 'aboveim',\n",
       " 'abovelist',\n",
       " 'aboveliv',\n",
       " 'abovelol',\n",
       " 'abovement',\n",
       " 'aboveno',\n",
       " 'abovenot',\n",
       " 'aboveor',\n",
       " 'aboveroomtemperatur',\n",
       " 'abovesmil',\n",
       " 'aboveso',\n",
       " 'abovethough',\n",
       " 'aboveto',\n",
       " 'abovewoah',\n",
       " 'abowl',\n",
       " 'abox',\n",
       " 'abr',\n",
       " 'abra',\n",
       " 'abracadab',\n",
       " 'abracadabra',\n",
       " 'abraham',\n",
       " 'abrahamhick',\n",
       " 'abrahamm',\n",
       " 'abrahm',\n",
       " 'abram',\n",
       " 'abramelin',\n",
       " 'abramov',\n",
       " 'abras',\n",
       " 'abrasivealthough',\n",
       " 'abrazo',\n",
       " 'abrazoseduardo',\n",
       " 'abrdgd',\n",
       " 'abreakfast',\n",
       " 'abreast',\n",
       " 'abrevi',\n",
       " 'abria',\n",
       " 'abridg',\n",
       " 'abril',\n",
       " 'abrir',\n",
       " 'abroad',\n",
       " 'abroadbut',\n",
       " 'abroadcountri',\n",
       " 'abroadmartha',\n",
       " 'abroadmayb',\n",
       " 'abroadmongolia',\n",
       " 'abroadw',\n",
       " 'abroadwhen',\n",
       " 'abromin',\n",
       " 'abroth',\n",
       " 'abrozo',\n",
       " 'abrubt',\n",
       " 'abrupt',\n",
       " 'absalom',\n",
       " 'absalomth',\n",
       " 'abscess',\n",
       " 'abscessstab',\n",
       " 'abscond',\n",
       " 'abseil',\n",
       " 'absenc',\n",
       " 'absencei',\n",
       " 'absencein',\n",
       " 'absens',\n",
       " 'absent',\n",
       " 'absente',\n",
       " 'absenti',\n",
       " 'absentia',\n",
       " 'absentmind',\n",
       " 'absentminded',\n",
       " 'absentmindedish',\n",
       " 'absentmindedprofessor',\n",
       " 'absentspati',\n",
       " 'absinth',\n",
       " 'absintheand',\n",
       " 'absjeez',\n",
       " 'abslegit',\n",
       " 'abslid',\n",
       " 'absnjunk',\n",
       " 'absoeffinglut',\n",
       " 'absoeffinlut',\n",
       " 'absofacto',\n",
       " 'absofrickinglut',\n",
       " 'absofrigginlut',\n",
       " 'absofuckinglut',\n",
       " 'absolout',\n",
       " 'absolult',\n",
       " 'absolut',\n",
       " 'absolutelycompletelyfascin',\n",
       " 'absolutelyessenti',\n",
       " 'absolutepunk',\n",
       " 'absolutey',\n",
       " 'absoluti',\n",
       " 'absolutist',\n",
       " 'absolutley',\n",
       " 'absolv',\n",
       " 'absonut',\n",
       " 'absorb',\n",
       " 'absorbingshar',\n",
       " 'absorbshar',\n",
       " 'absord',\n",
       " 'absorpt',\n",
       " 'absoul',\n",
       " 'absoult',\n",
       " 'absout',\n",
       " 'absquatul',\n",
       " 'absract',\n",
       " 'abstain',\n",
       " 'abstemi',\n",
       " 'abstin',\n",
       " 'abstinenceon',\n",
       " 'abstract',\n",
       " 'abstractartsi',\n",
       " 'abstractb',\n",
       " 'abstractexpressionisti',\n",
       " 'abstractgeometr',\n",
       " 'abstractlyfriendship',\n",
       " 'abstractphilosophicalartist',\n",
       " 'abstractpseudo',\n",
       " 'abstrud',\n",
       " 'abstrus',\n",
       " 'abstrusegoos',\n",
       " 'abstrusegoosecom',\n",
       " 'absu',\n",
       " 'absurb',\n",
       " 'absurd',\n",
       " 'absurdabsurd',\n",
       " 'absurdat',\n",
       " 'absurdem',\n",
       " 'absurdhilari',\n",
       " 'absurdinterest',\n",
       " 'absurdist',\n",
       " 'absurdistaan',\n",
       " 'absurdistan',\n",
       " 'absurdistsarcast',\n",
       " 'absurdistsurrealblack',\n",
       " 'absurdistsurrealist',\n",
       " 'absurditiesand',\n",
       " 'absurdityit',\n",
       " 'absurdo',\n",
       " 'absurdrandom',\n",
       " 'absynth',\n",
       " 'abt',\n",
       " 'abu',\n",
       " 'abubakr',\n",
       " 'abuela',\n",
       " 'abuelita',\n",
       " 'abuelito',\n",
       " 'abuelo',\n",
       " 'abugida',\n",
       " 'abujam',\n",
       " 'abulhawa',\n",
       " 'abulughod',\n",
       " 'abund',\n",
       " 'abundancei',\n",
       " 'abundantlyflavor',\n",
       " 'abundantplay',\n",
       " 'abundat',\n",
       " 'abunimah',\n",
       " 'aburrido',\n",
       " 'abus',\n",
       " 'abusedit',\n",
       " 'abusethink',\n",
       " 'abusin',\n",
       " 'abut',\n",
       " 'abuut',\n",
       " 'abuzz',\n",
       " 'abym',\n",
       " 'abysinian',\n",
       " 'abysm',\n",
       " 'abysmala',\n",
       " 'abyss',\n",
       " 'abyssinian',\n",
       " 'abyssmi',\n",
       " 'abyssus',\n",
       " 'abz',\n",
       " 'ac',\n",
       " 'acab',\n",
       " 'acacia',\n",
       " 'acad',\n",
       " 'acadami',\n",
       " 'acadamia',\n",
       " 'academ',\n",
       " 'academi',\n",
       " 'academia',\n",
       " 'academiaim',\n",
       " 'academianot',\n",
       " 'academiaresearch',\n",
       " 'academicallymind',\n",
       " 'academicallyori',\n",
       " 'academicathlet',\n",
       " 'academicbusi',\n",
       " 'academiccar',\n",
       " 'academici',\n",
       " 'academician',\n",
       " 'academicintellectu',\n",
       " 'academicorgan',\n",
       " 'academicrel',\n",
       " 'academicresearchersmartyp',\n",
       " 'academicslashwrit',\n",
       " 'academictour',\n",
       " 'academiy',\n",
       " 'academt',\n",
       " 'academyprob',\n",
       " 'academysfpd',\n",
       " 'acadeymi',\n",
       " 'acadm',\n",
       " 'acadmica',\n",
       " 'acaf',\n",
       " 'acai',\n",
       " 'acampar',\n",
       " 'acapella',\n",
       " 'acappella',\n",
       " 'acappellano',\n",
       " 'acapulco',\n",
       " 'acassano',\n",
       " 'acat',\n",
       " 'acaton',\n",
       " 'acc',\n",
       " 'accapella',\n",
       " 'acccent',\n",
       " 'acccess',\n",
       " 'acccord',\n",
       " 'accd',\n",
       " 'accel',\n",
       " 'acceler',\n",
       " 'accelerando',\n",
       " 'acceleratedsacr',\n",
       " 'accelerationintervent',\n",
       " 'acceleratorsdid',\n",
       " 'accellerando',\n",
       " 'accent',\n",
       " 'accentactu',\n",
       " 'accentand',\n",
       " 'accentbut',\n",
       " 'accentc',\n",
       " 'accentcharm',\n",
       " 'accentdontcha',\n",
       " 'accenteven',\n",
       " 'accenthop',\n",
       " 'accenti',\n",
       " 'accentim',\n",
       " 'accentit',\n",
       " 'accentlol',\n",
       " 'accentmi',\n",
       " 'accentobvi',\n",
       " 'accentor',\n",
       " 'accentsdialect',\n",
       " 'accentsimperson',\n",
       " 'accentsjust',\n",
       " 'accentsspeak',\n",
       " 'accentssubject',\n",
       " 'accentsvoicesimpress',\n",
       " 'accentu',\n",
       " 'accentugh',\n",
       " 'accentur',\n",
       " 'accentwel',\n",
       " 'accentwhich',\n",
       " 'accentwouldnt',\n",
       " 'accep',\n",
       " 'accept',\n",
       " 'acceptableawesom',\n",
       " 'acceptablefavor',\n",
       " 'acceptableim',\n",
       " 'acceptac',\n",
       " 'acceptancehealth',\n",
       " 'acceptedand',\n",
       " 'acceptembrac',\n",
       " 'acceptin',\n",
       " 'acceptingaccommod',\n",
       " 'acceptingopen',\n",
       " 'acceptor',\n",
       " 'accesor',\n",
       " 'accesori',\n",
       " 'access',\n",
       " 'accessalthough',\n",
       " 'accessconnect',\n",
       " 'accessexcept',\n",
       " 'accessissu',\n",
       " 'accessor',\n",
       " 'accessori',\n",
       " 'accessoriesit',\n",
       " 'accessorizedmanpurs',\n",
       " 'accessorizingb',\n",
       " 'accessorylifestyl',\n",
       " 'accessorythat',\n",
       " 'acchi',\n",
       " 'accid',\n",
       " 'accident',\n",
       " 'accidentgeezso',\n",
       " 'accidenti',\n",
       " 'accidentinjuri',\n",
       " 'accidentpron',\n",
       " 'accidentproneeven',\n",
       " 'accidentyeah',\n",
       " 'accion',\n",
       " 'acclaim',\n",
       " 'acclect',\n",
       " 'acclim',\n",
       " 'acclimatis',\n",
       " 'acclivisl',\n",
       " 'accolad',\n",
       " 'accomish',\n",
       " 'accomlish',\n",
       " 'accommod',\n",
       " 'accomod',\n",
       " 'accompani',\n",
       " 'accompanimentcompl',\n",
       " 'accompanist',\n",
       " 'accomphlish',\n",
       " 'accompli',\n",
       " 'accomplic',\n",
       " 'accomplish',\n",
       " 'accomplishand',\n",
       " 'accomplishedbut',\n",
       " 'accomplishedsuccess',\n",
       " 'accomplishedwarm',\n",
       " 'accomplishfootballrollin',\n",
       " 'accomplishi',\n",
       " 'accomplishmentgo',\n",
       " 'accomplishmentstir',\n",
       " 'accompni',\n",
       " 'accompolish',\n",
       " 'accomponi',\n",
       " 'acconci',\n",
       " 'accoplish',\n",
       " 'accord',\n",
       " 'accordeon',\n",
       " 'accordian',\n",
       " 'accordinglyupd',\n",
       " 'accordion',\n",
       " 'accordionand',\n",
       " 'accordionist',\n",
       " 'accordionista',\n",
       " 'accordionmotownshowtun',\n",
       " 'accordionplayingfolkdanc',\n",
       " 'accost',\n",
       " 'accostom',\n",
       " 'account',\n",
       " 'accountabilityintegr',\n",
       " 'accountablecamp',\n",
       " 'accountalso',\n",
       " 'accountantauditor',\n",
       " 'accountantfath',\n",
       " 'accountapp',\n",
       " 'accountblad',\n",
       " 'accountbut',\n",
       " 'accountfantasticwhich',\n",
       " 'accounth',\n",
       " 'accountingbusi',\n",
       " 'accountingeconom',\n",
       " 'accountingfin',\n",
       " 'accountingfinancemarketingeconom',\n",
       " 'accountingmarket',\n",
       " 'accountingrel',\n",
       " 'accountingsociolog',\n",
       " 'accountingsound',\n",
       " 'accountingwork',\n",
       " 'accountiphonemi',\n",
       " 'accountphon',\n",
       " 'accountproject',\n",
       " 'accountthat',\n",
       " 'accoust',\n",
       " 'accoustica',\n",
       " 'accousticani',\n",
       " 'accout',\n",
       " 'accouter',\n",
       " 'accoutr',\n",
       " 'accoutrementsinternet',\n",
       " 'accquaint',\n",
       " 'accredi',\n",
       " 'accredit',\n",
       " 'accret',\n",
       " 'accretionari',\n",
       " 'accross',\n",
       " 'accru',\n",
       " 'accrual',\n",
       " 'acct',\n",
       " 'acctual',\n",
       " 'accultur',\n",
       " 'accumben',\n",
       " 'accumil',\n",
       " 'accumsan',\n",
       " 'accumul',\n",
       " 'accupressur',\n",
       " 'accur',\n",
       " 'accura',\n",
       " 'accuraci',\n",
       " 'accurantlli',\n",
       " 'accurat',\n",
       " 'accuratealmost',\n",
       " 'accuratei',\n",
       " 'accuratelyhonest',\n",
       " 'accurateridicul',\n",
       " 'accuratewhen',\n",
       " 'accurs',\n",
       " 'accus',\n",
       " 'accusamus',\n",
       " 'accusedprais',\n",
       " 'accuss',\n",
       " 'accust',\n",
       " 'accustom',\n",
       " 'accut',\n",
       " 'acdc',\n",
       " 'acdcdokkenrushbad',\n",
       " 'acdcer',\n",
       " 'acdcqueen',\n",
       " 'acdcth',\n",
       " 'acdemi',\n",
       " 'acdhonncha',\n",
       " 'acdsh',\n",
       " 'ace',\n",
       " 'aceartsblogspotcom',\n",
       " 'acecdot',\n",
       " 'acediast',\n",
       " 'aceinthehol',\n",
       " 'acelyon',\n",
       " 'acemoglu',\n",
       " 'acen',\n",
       " 'acent',\n",
       " 'acento',\n",
       " 'acer',\n",
       " 'acerb',\n",
       " 'acerbicstan',\n",
       " 'acess',\n",
       " 'acessori',\n",
       " 'acetaldehyd',\n",
       " 'acetastin',\n",
       " 'aceton',\n",
       " 'acetylcholin',\n",
       " 'acetylen',\n",
       " 'acey',\n",
       " 'aceyalon',\n",
       " 'ach',\n",
       " 'acham',\n",
       " 'achangin',\n",
       " 'achapela',\n",
       " 'achar',\n",
       " 'achari',\n",
       " 'acharya',\n",
       " 'achatz',\n",
       " 'achavalferr',\n",
       " 'achbar',\n",
       " 'acheb',\n",
       " 'achef',\n",
       " 'acheiv',\n",
       " 'acher',\n",
       " 'achewood',\n",
       " 'achhhhh',\n",
       " 'achi',\n",
       " 'achidi',\n",
       " 'achiev',\n",
       " 'achievedi',\n",
       " 'achieveetc',\n",
       " 'achievei',\n",
       " 'achievementcent',\n",
       " 'achievementgrowth',\n",
       " 'achievementori',\n",
       " 'achievementsfutur',\n",
       " 'achievemi',\n",
       " 'achieverobserv',\n",
       " 'achievesometh',\n",
       " 'achievingmaintain',\n",
       " 'achill',\n",
       " 'achillea',\n",
       " 'achilleus',\n",
       " 'achim',\n",
       " 'achinoam',\n",
       " 'achiot',\n",
       " 'achiv',\n",
       " 'achm',\n",
       " 'achmat',\n",
       " 'acho',\n",
       " 'achondroplast',\n",
       " 'achoo',\n",
       " 'achoooo',\n",
       " 'achromat',\n",
       " 'achtung',\n",
       " 'achuar',\n",
       " 'acid',\n",
       " 'acidbreak',\n",
       " 'acidcountri',\n",
       " 'acidfolk',\n",
       " 'acidifi',\n",
       " 'acidjazz',\n",
       " 'acidjazzfolk',\n",
       " 'acidradiohead',\n",
       " 'acidtechno',\n",
       " 'acidtongu',\n",
       " 'acidtr',\n",
       " 'acient',\n",
       " 'acim',\n",
       " 'aciman',\n",
       " 'acion',\n",
       " 'acit',\n",
       " 'acito',\n",
       " 'ack',\n",
       " 'acka',\n",
       " 'ackawackalackayak',\n",
       " 'acker',\n",
       " 'ackerman',\n",
       " 'ackermanfellow',\n",
       " 'ackermann',\n",
       " 'ackk',\n",
       " 'ackley',\n",
       " 'acknoledg',\n",
       " 'acknowledg',\n",
       " 'acknowledgeb',\n",
       " 'acknowledgebastard',\n",
       " 'acknowledgeembracewelcom',\n",
       " 'acknowledgingshar',\n",
       " 'acknowlegd',\n",
       " 'ackroyd',\n",
       " 'ackryod',\n",
       " 'ackward',\n",
       " 'ackwardwel',\n",
       " 'acl',\n",
       " 'aclam',\n",
       " 'aclchemist',\n",
       " 'aclcoachellaoutsid',\n",
       " 'aclu',\n",
       " 'acm',\n",
       " 'acmt',\n",
       " 'acn',\n",
       " 'acncestor',\n",
       " 'acoast',\n",
       " 'acohol',\n",
       " 'acolor',\n",
       " 'acolyt',\n",
       " 'acomfyb',\n",
       " 'acomin',\n",
       " 'acompanhava',\n",
       " 'acompani',\n",
       " 'acomplish',\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
