{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, xyz2lab\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('X_tundra.pkl', 'rb') as handle:\n",
    "        X = pickle.load(handle)\n",
    "except:\n",
    "    path = './unzipped_images/tundra/'\n",
    "    X = []\n",
    "    for filename in os.listdir(path):\n",
    "        X.append(img_to_array(load_img(path + filename))/255)\n",
    "    X = np.array(X)\n",
    "    with open('X_tundra.pkl', 'wb') as handle:\n",
    "        pickle.dump(X, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = X[:4500]\n",
    "Xval = X[4500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "batch_size = 32\n",
    "def train_generator(batch_size):\n",
    "    for batch in train_datagen.flow(Xtrain, batch_size=batch_size):\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        X_batch = lab_batch[:,:,:,0] / 100 # scale to [0, 1] bc neural networks prefer small input values\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "def val_generator(batch_size):\n",
    "    for batch in val_datagen.flow(Xtrain, batch_size=batch_size):\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        X_batch = lab_batch[:,:,:,0] / 100 # scale to [0, 1] bc neural networks prefer small input values\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_like(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(256, 256, 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "    \n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG_like()\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "4/4 [==============================] - 469s 117s/step - loss: 0.1450 - val_loss: 0.0127\n",
      "Epoch 2/10000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(\n",
    "    train_generator(batch_size),\n",
    "    steps_per_epoch=len(Xtrain)/batch_size,\n",
    "    epochs=10000,\n",
    "    validation_data=val_generator(batch_size),\n",
    "    validation_steps=len(Xval)/batch_size,\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=20),\n",
    "             ModelCheckpoint(filepath='best_model_small.h5', monitor='val_loss', save_best_only=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
